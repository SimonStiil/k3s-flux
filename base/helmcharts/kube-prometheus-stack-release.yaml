---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: kube-prometheus-stack
  namespace: flux-system
spec:
  chart:
    spec:
      chart: kube-prometheus-stack
      version: 81.0.0
      reconcileStrategy: ChartVersion
      sourceRef:
        kind: HelmRepository
        name: prometheus-community
  install:
    crds: CreateReplace
    createNamespace: true
  upgrade:
    crds: CreateReplace
  interval: 10m0s
  targetNamespace: monitoring
  valuesFrom:
  - kind: ConfigMap
    name: kube-prometheus-stack-values
    valuesKey: kube-state-metrics-config.yaml
  values:
    fullnameOverride: prometheus
    defaultRules:
      create: true
      rules:
        alertmanager: true
        etcd: true
        configReloaders: true
        general: true
        k8s: true
        kubeApiserverAvailability: true
        kubeApiserverBurnrate: true
        kubeApiserverHistogram: true
        kubeApiserverSlos: true
        kubelet: true
        kubeProxy: true
        kubePrometheusGeneral: true
        kubePrometheusNodeRecording: true
        kubernetesApps: true
        kubernetesResources: true
        kubernetesStorage: true
        kubernetesSystem: true
        kubeScheduler: true
        kubeStateMetrics: true
        network: true
        node: true
        nodeExporterAlerting: true
        nodeExporterRecording: true
        prometheus: true
        prometheusOperator: true
    alertmanager:
      fullnameOverride: alertmanager
      enabled: true
      ingress:
        enabled: false
      serviceMonitor:
        relabelings:
          - targetLabel: "cluster"
            replacement: "k3s"
    grafana:
      enabled: true
      revisionHistoryLimit: 2
      fullnameOverride: grafana
      forceDeployDatasources: false
      forceDeployDashboards: false
      defaultDashboardsEnabled: true
      defaultDashboardsTimezone: utc
      serviceMonitor:
        enabled: true
        relabelings:
          - targetLabel: "cluster"
            replacement: "k3s"
      admin:
        existingSecret: grafana-admin-credentials
        userKey: admin-user
        passwordKey: admin-password
      grafana.ini:
        auth.ldap:
          enabled: true
          allow_sign_up: true
          config_file: /etc/grafana/ldap.toml
        server:
          root_url: https://grafana.${clusterdomain:=undefined}/
#        auth: 
#          oauth_auto_login: true
#          oauth_allow_insecure_email_lookup: true
#        auth.generic_oauth:
#          enabled: true
#          name: Authelia
#          scopes: "openid email profile groups"
#          use_refresh_token: true
#          auth_url: "https://auth.${topleveldomain:=undefined}/api/oidc/authorization"
#          token_url: "https://auth.${topleveldomain:=undefined}/api/oidc/token"
#          api_url: "https://auth.${topleveldomain:=undefined}/api/oidc/userinfo"
#          login_attribute_path: preferred_username
#          allow_assign_grafana_admin: true
#          auto_login: true
#          use_pkce: true
#          email_attribute_path: email
#          role_attribute_path: "contains(groups[*], 'administrators') && 'Admin' || contains(groups[*], 'developer') && 'Editor' || 'Viewer'"
#      envFromSecret: grafana-generic-oauth-env
      ldap:
        enabled: true
        existingSecret: grafana-ldap-credentials
      deploymentStrategy:
        type: Recreate
      ingress:
        enabled: true
        ingressClassName: traefik
        annotations: 
          traefik.ingress.kubernetes.io/router.entrypoints: websecure,web
          traefik.ingress.kubernetes.io/router.tls: "true"
        hosts:
         - grafana.${clusterdomain:=undefined}
      persistence:
        enabled: true
        type: pvc
        storageClassName: "nfs-csi"
        accessModes:
        - ReadWriteOnce
        size: 4Gi
      additionalDataSources:
      - name: Loki
        type: loki
        uid: loki
        access: proxy
        url: http://loki-headless:3100
        version: 1
        isDefault: false
        editable: false
        label: loki_datasource
        labelValue: "1"
        jsonData: {}
    persistence:
      enabled: true
      type: sts
      storageClassName: "nfs-csi"
      accessModes:
        - ReadWriteOnce
      size: 20Gi     
    kubeApiServer:
      enabled: true
      serviceMonitor:
        relabelings:
          - targetLabel: "cluster"
            replacement: "k3s"
    kubelet:
      enabled: true
      serviceMonitor:
        relabelings:
          - action: replace
            sourceLabels: [__metrics_path__]
            targetLabel: metrics_path
          - action: replace
            sourceLabels:
              - node
            targetLabel: instance
          - targetLabel: "cluster"
            replacement: "k3s"
        cAdvisorRelabelings:
          - action: replace
            sourceLabels: [__metrics_path__]
            targetLabel: metrics_path
          - targetLabel: "cluster"
            replacement: "k3s"
        probesRelabelings:
          - action: replace
            sourceLabels: [__metrics_path__]
            targetLabel: metrics_path
          - targetLabel: "cluster"
            replacement: "k3s"
        resourceRelabelings:
          - action: replace
            sourceLabels: [__metrics_path__]
            targetLabel: metrics_path
          - targetLabel: "cluster"
            replacement: "k3s"
    kubeControllerManager:
      enabled: true
      endpoints: # ips of servers 
        - 192.168.10.110
      serviceMonitor:
        relabelings:
          - targetLabel: "cluster"
            replacement: "k3s"
    coreDns:
      enabled: true
      serviceMonitor:
        relabelings:
          - targetLabel: "cluster"
            replacement: "k3s"
    kubeDns:
      enabled: false
    kubeEtcd:
      enabled: true
      endpoints: # ips of servers
        - 192.168.10.110
      service:
        enabled: true
        port: 2381
        targetPort: 2381
      serviceMonitor:
        relabelings:
          - targetLabel: "cluster"
            replacement: "k3s"
    kubeScheduler:
      enabled: true
      endpoints: # ips of servers
        - 192.168.10.110
      serviceMonitor:
        relabelings:
          - targetLabel: "cluster"
            replacement: "k3s"
    kubeProxy:
      enabled: true
      endpoints: # ips of servers
        - 192.168.10.110
      serviceMonitor:
        relabelings:
          - targetLabel: "cluster"
            replacement: "k3s"
    kubeStateMetrics:
      enabled: true
    kube-state-metrics:
      fullnameOverride: kube-state-metrics
      selfMonitor:
        enabled: true
      prometheus:
        monitor:
          enabled: true
          relabelings:
            - action: replace
              regex: (.*)
              replacement: $1
              sourceLabels:
                - __meta_kubernetes_pod_node_name
              targetLabel: kubernetes_node
            - targetLabel: "cluster"
              replacement: "k3s"
      revisionHistoryLimit: 2
    nodeExporter:
      enabled: true
      serviceMonitor:
        relabelings:
          - action: replace
            regex: (.*)
            replacement: $1
            sourceLabels:
              - __meta_kubernetes_pod_node_name
            targetLabel: kubernetes_node
          - targetLabel: "cluster"
            replacement: "k3s"
    prometheus-node-exporter:
      fullnameOverride: node-exporter
      podLabels:
        jobLabel: node-exporter
      podAnnotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
        container.apparmor.security.beta.kubernetes.io/node-exporter: "unconfined"
      extraArgs:
        - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|run|var/lib/docker/.+|var/lib/kubelet/.+)($|/)
        - --collector.filesystem.fs-types-exclude=^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$
        - --collector.processes
      containerSecurityContext:
        readOnlyRootFilesystem: true
        capabilities:
          add:
          - SYS_TIME
          - SYS_PTRACE
      service:
        portName: http-metrics
      prometheus:
        monitor:
          enabled: true
          relabelings:
            - action: replace
              regex: (.*)
              replacement: $1
              sourceLabels:
                - __meta_kubernetes_pod_node_name
              targetLabel: kubernetes_node
            - targetLabel: "cluster"
              replacement: "k3s"
    prometheusOperator:
      enabled: true
      serviceMonitor:
        relabelings:
          - targetLabel: "cluster"
            replacement: "k3s"
      revisionHistoryLimit: 2
    prometheus:
      enabled: true
      prometheusSpec:
        replicas: 1
        replicaExternalLabelName: "replica"
        ruleSelectorNilUsesHelmValues: false
        serviceMonitorSelectorNilUsesHelmValues: false
        podMonitorSelectorNilUsesHelmValues: false
        probeSelectorNilUsesHelmValues: false
        retention: 48h
        enableAdminAPI: true
        walCompression: true
        storageSpec:
          volumeClaimTemplate:
            spec:
              storageClassName: nfs-csi
              accessModes: ["ReadWriteOnce"]
              resources:
                requests:
                  storage: 50Gi
      serviceMonitor:
        relabelings:
          - targetLabel: "cluster"
            replacement: "k3s"
      ingress:
        enabled: true
        hosts:
         - prometheus.k3s.${homedomain:=undefined}
        annotations:
          cert-manager.io/cluster-issuer: stiil-issuer
          traefik.ingress.kubernetes.io/router.entrypoints: websecure,web
          traefik.ingress.kubernetes.io/router.tls: "true"
        ingressClassName: traefik
        tls:
        - secretName: prometheus-cert
          hosts:
          - prometheus.k3s.${homedomain:=undefined}
    thanosRuler:
      enabled: false